{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport pickle\n\nfrom math import sin, cos, pi\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.layers import Flatten, Conv2D, LeakyReLU, GlobalAveragePooling2D, MaxPooling2D, Dropout, Dense\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\ntf.random.set_seed(18)\nnp.random.seed(18)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:22.193682Z","iopub.execute_input":"2022-08-31T15:51:22.194236Z","iopub.status.idle":"2022-08-31T15:51:30.31933Z","shell.execute_reply.started":"2022-08-31T15:51:22.194147Z","shell.execute_reply":"2022-08-31T15:51:30.31827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"!unzip ../input/facial-keypoints-detection/training.zip\n!unzip ../input/facial-keypoints-detection/test.zip\n\ntrain_data = pd.read_csv('./training.csv')\ntest_data = pd.read_csv('./test.csv')\nlookid_data = pd.read_csv('../input/facial-keypoints-detection/IdLookupTable.csv')\n\nprint(train_data.shape, test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:30.321418Z","iopub.execute_input":"2022-08-31T15:51:30.322167Z","iopub.status.idle":"2022-08-31T15:51:38.967851Z","shell.execute_reply.started":"2022-08-31T15:51:30.322125Z","shell.execute_reply":"2022-08-31T15:51:38.966447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First look at the data","metadata":{}},{"cell_type":"code","source":"# Take a look at the sample data\npd.set_option(\"display.max_columns\", 100)\n\ntrain_data[:3].T","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:38.969888Z","iopub.execute_input":"2022-08-31T15:51:38.970289Z","iopub.status.idle":"2022-08-31T15:51:38.998534Z","shell.execute_reply.started":"2022-08-31T15:51:38.970247Z","shell.execute_reply":"2022-08-31T15:51:38.997374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:39.001192Z","iopub.execute_input":"2022-08-31T15:51:39.001689Z","iopub.status.idle":"2022-08-31T15:51:39.032016Z","shell.execute_reply.started":"2022-08-31T15:51:39.001652Z","shell.execute_reply":"2022-08-31T15:51:39.031028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above, we see quite a number of columns that contain missing values, and the number of missing values are large.","metadata":{}},{"cell_type":"code","source":"test_data[:3]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:39.035074Z","iopub.execute_input":"2022-08-31T15:51:39.035918Z","iopub.status.idle":"2022-08-31T15:51:39.048565Z","shell.execute_reply.started":"2022-08-31T15:51:39.03587Z","shell.execute_reply":"2022-08-31T15:51:39.047023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each cell in Column 'image' in train_data/test_data is a list composed of 96*96=9216 items which are seperated by space from each other. This is the X (fields) while y is the other 30 columns in train_data.","metadata":{}},{"cell_type":"markdown","source":"# Handle missing values","metadata":{}},{"cell_type":"code","source":"# Now we deal with missing values\n\nprint(\"How many columns contain missing values?\")\nprint(train_data.isnull().any().value_counts())\nprint(\"------------------\")\nprint(\"The number of missing values for each column:\")\nprint(train_data.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:39.05136Z","iopub.execute_input":"2022-08-31T15:51:39.052021Z","iopub.status.idle":"2022-08-31T15:51:39.067422Z","shell.execute_reply.started":"2022-08-31T15:51:39.051993Z","shell.execute_reply":"2022-08-31T15:51:39.066455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Size of original dataframe: \"+str(len(train_data))+'x'+str(len(train_data.columns))+'\\n')\ntrain_aug = train_data.dropna()\nprint(\"Size of dataframe after dropping rows of missing values, which is used for data augmentation: \"\n      +str(len(train_aug))+'x'+str(len(train_aug.columns))+'\\n')","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:39.070273Z","iopub.execute_input":"2022-08-31T15:51:39.071073Z","iopub.status.idle":"2022-08-31T15:51:39.083378Z","shell.execute_reply.started":"2022-08-31T15:51:39.071044Z","shell.execute_reply":"2022-08-31T15:51:39.082047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One option: fill the missing values with the previous values in that row\ntrain_fill = train_data.fillna(method = 'ffill')\nprint(\"Size of dataframe after filling blanks: \"\n      +str(len(train_fill))+'x'+str(len(train_fill.columns))+'\\n')","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:39.084864Z","iopub.execute_input":"2022-08-31T15:51:39.085319Z","iopub.status.idle":"2022-08-31T15:51:39.098928Z","shell.execute_reply.started":"2022-08-31T15:51:39.085282Z","shell.execute_reply":"2022-08-31T15:51:39.097415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we have such a great amount of missing values, we simply cannot drop them. We still include them for the analyses, but we will not use them for augmentation.","metadata":{}},{"cell_type":"markdown","source":"# Prepare X and y","metadata":{}},{"cell_type":"code","source":"def prep_x_y (train):\n    \"\"\"\n    Function to extract X and y from training set:\n    INPUT:\n        train: dataframe with shape (n,31)\n    OUTPUT:\n        X: numpy array which contains image data, shape (n,96,96,1)\n        y: numpy array with shape (n, 30)\n    \"\"\"\n    imgs = []\n    pnts = []\n    \n    n = train.shape[0]\n    \n    X_tr = train['Image'] # X part\n    y_tr = train.drop('Image',axis = 1) # y part\n    \n    for i in range(n):\n        img = X_tr.iloc[i]\n        img = img.split(' ')\n        imgs.append(img)\n        \n        pnt = y_tr.iloc[i,:] # take the ith row data\n        pnts.append(pnt)\n\n    X_train = np.array(imgs,dtype = 'float')\n    X_train = X_train.reshape(-1,96,96,1)\n    y_train = np.array(pnts,dtype = 'float')\n    X_train = X_train / 255.0\n    \n    return X_train, y_train","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:39.100903Z","iopub.execute_input":"2022-08-31T15:51:39.101618Z","iopub.status.idle":"2022-08-31T15:51:39.111558Z","shell.execute_reply.started":"2022-08-31T15:51:39.101582Z","shell.execute_reply":"2022-08-31T15:51:39.110381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# These are used as base for image augmentation\n\nX_aug, y_aug = prep_x_y(train_aug)\n\nprint(X_aug.shape)\nprint(X_aug.min(), X_aug.max())\nprint(\"\")\n\nprint(y_aug.shape)\nprint(y_aug.min(), y_aug.max())","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:39.116924Z","iopub.execute_input":"2022-08-31T15:51:39.117289Z","iopub.status.idle":"2022-08-31T15:51:43.63147Z","shell.execute_reply.started":"2022-08-31T15:51:39.11726Z","shell.execute_reply":"2022-08-31T15:51:43.630338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# These are to be included in the final training set\n\nX_fill, y_fill = prep_x_y(train_fill)\n\nprint(X_fill.shape)\nprint(X_fill.min(), X_fill.max())\n\nprint(y_fill.shape)\nprint(y_fill.min(), y_fill.max())","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:43.633054Z","iopub.execute_input":"2022-08-31T15:51:43.633509Z","iopub.status.idle":"2022-08-31T15:51:59.566793Z","shell.execute_reply.started":"2022-08-31T15:51:43.633472Z","shell.execute_reply":"2022-08-31T15:51:59.565572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that the range for y is (0,96), after image augmentation, we need to make sure the augmented data still falls within this range.","metadata":{}},{"cell_type":"markdown","source":"# Plot some images","metadata":{}},{"cell_type":"code","source":"def plot_images(images, points, ncols, shrinkage=0.2):\n  \"\"\"\n  Function to plot images and their lables:\n  INPUT:\n      images: numpy array with shape (N, d, d, c) dtype=float\n      points: numpy array with shape (N,), dtype=float\n      ncols: number of columns in the resulting image grid\n      shrinage: how much each image to be shrinked for display\n  \"\"\"\n  \n  nindex, height, width, intensity = images.shape\n  nrows = nindex//ncols\n  print(f\"Number of rows: {nrows}, number of cols: {ncols}\")\n  \n  fig_width = int(width*ncols*shrinkage)\n  fig_height = int(height*nrows*shrinkage)\n\n  fig, axes = plt.subplots(nrows, ncols, \n                          figsize=(fig_width, fig_height))\n  print(f\"Figure width: {fig_width}, height: {fig_height}\")\n  axes = axes.flatten()\n  \n  for k in range(nindex):\n    img = images[k]\n    img = array_to_img(img)\n    ax = axes[k]\n    ax.imshow(img, cmap=\"Greys_r\")\n    pnt_x = [points[k][2*j] for j in range(15)]\n    pnt_y = [points[k][2*j+1] for j in range(15)]\n    ax.scatter(pnt_x,pnt_y,s=50,c='r')\n    ax.set_axis_off()\n\n  plt.tight_layout()\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:59.568544Z","iopub.execute_input":"2022-08-31T15:51:59.568978Z","iopub.status.idle":"2022-08-31T15:51:59.578546Z","shell.execute_reply.started":"2022-08-31T15:51:59.568937Z","shell.execute_reply":"2022-08-31T15:51:59.577297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(X_aug[:12], y_aug[:12], 6, shrinkage=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:51:59.580299Z","iopub.execute_input":"2022-08-31T15:51:59.581008Z","iopub.status.idle":"2022-08-31T15:52:01.346092Z","shell.execute_reply.started":"2022-08-31T15:51:59.580969Z","shell.execute_reply":"2022-08-31T15:52:01.345212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Augmentation with cv2","metadata":{}},{"cell_type":"markdown","source":"## Define helper functions","metadata":{}},{"cell_type":"code","source":"def aug_rotation(X, y, rotation_angles=[15]):\n    \"\"\"\n    Function to rotate images (X) and points (y) in the same time.\n    INPUT:\n    \tX: numpy array with shape (n, d, d, c)\n    \ty: points to plot with shape (n, m)\n        rotation_angles: a list of angles to rotate\n    OUTPUT:\n        augmented images with shape (n, d, d, c)\n        augmented points with shape (n, m)\n\n    \"\"\"\n\n    rotated_images = []\n    rotated_keypoints = []\n    \n    size = X.shape[1] # suppose h == w\n    \n    center = (int(size/2), int(size/2))\n    \n    for angle in rotation_angles:\n        for angle in [angle, -angle]:\n            rot = cv2.getRotationMatrix2D(center, angle, 1.)\n            angle_rad = -angle*pi/180.\n            \n            for image in X:\n                rotated_image = cv2.warpAffine(image.reshape(size,size), rot, (size, size), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n                \n            for keypoint in y:\n                rotated_keypoint = keypoint - int(size/2)\n                \n                for idx in range(0, len(rotated_keypoint), 2):\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += size/2   \n                rotated_keypoints.append(rotated_keypoint)\n    \n    return np.reshape(rotated_images,(-1,size,size,1)), np.array(rotated_keypoints)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:01.347484Z","iopub.execute_input":"2022-08-31T15:52:01.348829Z","iopub.status.idle":"2022-08-31T15:52:01.362525Z","shell.execute_reply.started":"2022-08-31T15:52:01.348789Z","shell.execute_reply":"2022-08-31T15:52:01.361275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def aug_shift(X, y, pixel_shifts=[15]):\n    \"\"\"\n    Function to shift images (X) and points (y) in the same time.\n    INPUT:\n    \tX: numpy array with shape (n, d, d, c)\n    \ty: points to plot with shape (n, m)\n        pixel_shifts: a list of values indicating horizontal & vertical shift amount in pixels\n    OUTPUT:\n        augmented images with shape (n, d, d, c)\n        augmented points with shape (n, m)\n    \"\"\"\n    size = X.shape[1]\n    shifted_images = []\n    shifted_keypoints = []\n    for shift in pixel_shifts:    \n        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n            sh = np.float32([[1,0,shift_x],[0,1,shift_y]])\n            \n            for image, keypoint in zip(X, y):\n                shifted_image = cv2.warpAffine(image, sh, (size,size), flags=cv2.INTER_CUBIC)\n                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n                \n                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<size):\n                    shifted_images.append(shifted_image.reshape(size,size,1))\n                    shifted_keypoints.append(shifted_keypoint)\n    shifted_keypoints = np.clip(shifted_keypoints,0.0,size)\n    return np.array(shifted_images), np.array(shifted_keypoints)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:01.36465Z","iopub.execute_input":"2022-08-31T15:52:01.365639Z","iopub.status.idle":"2022-08-31T15:52:01.377531Z","shell.execute_reply.started":"2022-08-31T15:52:01.365601Z","shell.execute_reply":"2022-08-31T15:52:01.37651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def aug_brightness(X, y, brightness_range=[0.6,1.2]):\n    \"\"\"\n    Function to adjust the brightness of images (X) \n    INPUT:\n    \tX: numpy array with shape (n, d, d, c)\n    \ty: points to plot with shape (n, m)\n        brightness_range: a list of two values to decrease/increase brightness\n    OUTPUT:\n        augmented images with shape (n, d, d, c)\n        augmented points with shape (n, m)\n    Note:\n        Brightness is pre-defined as either 1.2 times or 0.6 times\n    \"\"\"\n    altered_brightness_images = []\n    inc_brightness_images = np.clip(X*brightness_range[1], 0, 255)    \n    dec_brightness_images = np.clip(X*brightness_range[0], 0, 255)    \n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return np.array(altered_brightness_images), np.concatenate((y, y))","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:01.379531Z","iopub.execute_input":"2022-08-31T15:52:01.380569Z","iopub.status.idle":"2022-08-31T15:52:01.391859Z","shell.execute_reply.started":"2022-08-31T15:52:01.380532Z","shell.execute_reply":"2022-08-31T15:52:01.390827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def aug_noise(X, y, noise=0.008):\n    \"\"\"\n    Function to add noises images (X) \n    INPUT:\n    \tX: numpy array with shape (n, d, d, c)\n    \ty: points to plot with shape (n, m)\n        noise: a value times a random number of normal distribution as noise impact\n    OUTPUT:\n        augmented images with shape (n, d, d, c)\n        augmented points with shape (n, m)\n    \"\"\"\n    noisy_images = []\n    size = X.shape[1]\n    for image in X:\n        noisy_image = cv2.add(image, noise*np.random.randn(size,size,1))    \n        noisy_images.append(noisy_image.reshape(size,size,1))\n    return np.array(noisy_images), y","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:01.393434Z","iopub.execute_input":"2022-08-31T15:52:01.39401Z","iopub.status.idle":"2022-08-31T15:52:01.406409Z","shell.execute_reply.started":"2022-08-31T15:52:01.393972Z","shell.execute_reply":"2022-08-31T15:52:01.405392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Apply functions","metadata":{}},{"cell_type":"code","source":"X_rot, y_rot = aug_rotation(X_aug,y_aug)\nprint(X_rot.shape)\nplot_images(X_rot[:12], y_rot[:12], 6, shrinkage=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:01.408136Z","iopub.execute_input":"2022-08-31T15:52:01.40914Z","iopub.status.idle":"2022-08-31T15:52:04.075935Z","shell.execute_reply.started":"2022-08-31T15:52:01.409099Z","shell.execute_reply":"2022-08-31T15:52:04.074974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_shift, y_shift = aug_shift(X_aug,y_aug)\nprint(X_shift.shape)\nplot_images(X_shift[:12], y_shift[:12], 6, shrinkage=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:04.077289Z","iopub.execute_input":"2022-08-31T15:52:04.077897Z","iopub.status.idle":"2022-08-31T15:52:08.137684Z","shell.execute_reply.started":"2022-08-31T15:52:04.077859Z","shell.execute_reply":"2022-08-31T15:52:08.136737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_brt, y_brt = aug_brightness(X_aug,y_aug)\nprint(X_brt.shape)\nplot_images(X_brt[:12], y_brt[:12], 6, shrinkage=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:08.139015Z","iopub.execute_input":"2022-08-31T15:52:08.140084Z","iopub.status.idle":"2022-08-31T15:52:10.148094Z","shell.execute_reply.started":"2022-08-31T15:52:08.140039Z","shell.execute_reply":"2022-08-31T15:52:10.143798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_noise, y_noise = aug_noise(X_aug,y_aug)\nprint(X_noise.shape)\nplot_images(X_noise[:12], y_noise[:12], 6, shrinkage=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:10.14994Z","iopub.execute_input":"2022-08-31T15:52:10.150643Z","iopub.status.idle":"2022-08-31T15:52:12.620135Z","shell.execute_reply.started":"2022-08-31T15:52:10.150605Z","shell.execute_reply":"2022-08-31T15:52:12.61913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate final training data","metadata":{}},{"cell_type":"code","source":"# First check all shapes\nprint(X_noise.shape, y_noise.shape)\nprint(X_brt.shape, y_brt.shape)\nprint(X_shift.shape, y_shift.shape)\nprint(X_rot.shape, y_rot.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:12.621777Z","iopub.execute_input":"2022-08-31T15:52:12.622883Z","iopub.status.idle":"2022-08-31T15:52:12.630058Z","shell.execute_reply.started":"2022-08-31T15:52:12.622843Z","shell.execute_reply":"2022-08-31T15:52:12.628922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.concatenate((X_fill, X_noise, X_brt, X_shift, X_rot))\ny = np.concatenate((y_fill, y_noise, y_brt, y_shift, y_rot))\n\nprint(X.shape, y.shape)\nprint(X.min(), \"----\",X.max())\nprint(y.min(), \"----\", y.max())","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:12.631941Z","iopub.execute_input":"2022-08-31T15:52:12.632905Z","iopub.status.idle":"2022-08-31T15:52:13.516419Z","shell.execute_reply.started":"2022-08-31T15:52:12.632866Z","shell.execute_reply":"2022-08-31T15:52:13.515287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build the model","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential()\npretrained_model = ResNet50(input_shape=(96,96,3), include_top=False, weights='imagenet')\npretrained_model.trainable = True\n\nmodel.add(Conv2D(3, (1,1), padding='same', input_shape=(96,96,1)))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(pretrained_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.1))\nmodel.add(Dense(30))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:13.518233Z","iopub.execute_input":"2022-08-31T15:52:13.518744Z","iopub.status.idle":"2022-08-31T15:52:19.046476Z","shell.execute_reply.started":"2022-08-31T15:52:13.518704Z","shell.execute_reply":"2022-08-31T15:52:19.045337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define callbacks\n\n# Early stopping if no improvement\nearly_stop = EarlyStopping(monitor = 'loss', \n                           patience = 30, \n                           mode = 'min',\n                           baseline=None)\n\n# Reduce learning rate when a metric has stopped improving.\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss', \n                              factor = 0.7,\n                              patience = 5, \n                              min_lr = 1e-15,\n                              mode = 'min', \n                              verbose = 1)\n\n# Compile the model\n\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:19.047945Z","iopub.execute_input":"2022-08-31T15:52:19.051398Z","iopub.status.idle":"2022-08-31T15:52:19.0689Z","shell.execute_reply.started":"2022-08-31T15:52:19.051363Z","shell.execute_reply":"2022-08-31T15:52:19.067867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"history=model.fit(x=X,\n                  y=y,\n                  epochs=200,\n                  batch_size=64,\n                  validation_split=0.15,\n                  callbacks=[early_stop,reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:52:19.0708Z","iopub.execute_input":"2022-08-31T15:52:19.071192Z","iopub.status.idle":"2022-08-31T17:05:20.849093Z","shell.execute_reply.started":"2022-08-31T15:52:19.071154Z","shell.execute_reply":"2022-08-31T17:05:20.848175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model\n\nmodel.save(\"FKD_KB1V1_E_Result-Model-ResNet50.h5\")\n\nwith open('FKD_KB1V1_E_Result-History-ResNet50.pkl', 'wb') as f:\n    pickle.dump(history.history, f)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T17:05:20.851465Z","iopub.execute_input":"2022-08-31T17:05:20.8526Z","iopub.status.idle":"2022-08-31T17:05:49.346561Z","shell.execute_reply.started":"2022-08-31T17:05:20.852561Z","shell.execute_reply":"2022-08-31T17:05:49.345566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Acc and Loss","metadata":{}},{"cell_type":"code","source":"def plot_acc_loss(history):\n    \"\"\"\n    Function to plot acc and loss of the training results:\n    INPUT:\n        history: object of the model fitting results\n    OUT:\n        A plot of training and validation acc per epoch\n        A plot of training and validation loss per opoch\n    \"\"\"\n    # Plot loss and acc \n\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    #------------------------------------------------\n    # Plot training and validation acc per epoch\n    #------------------------------------------------\n    plt.plot(epochs, acc, 'r', label='Training acc')\n    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n    plt.title('Training and validation acc')\n    plt.legend()\n    plt.figure()\n    print(\"\")\n\n    #------------------------------------------------\n    # Plot training and validation loss per epoch\n    #------------------------------------------------\n    plt.plot(epochs, loss, 'r', label='Training Loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T17:05:49.352137Z","iopub.execute_input":"2022-08-31T17:05:49.35247Z","iopub.status.idle":"2022-08-31T17:05:49.360126Z","shell.execute_reply.started":"2022-08-31T17:05:49.352441Z","shell.execute_reply":"2022-08-31T17:05:49.35915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_acc_loss(history)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T17:05:49.361559Z","iopub.execute_input":"2022-08-31T17:05:49.3626Z","iopub.status.idle":"2022-08-31T17:05:49.789318Z","shell.execute_reply.started":"2022-08-31T17:05:49.362514Z","shell.execute_reply":"2022-08-31T17:05:49.788331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict the Test Dataet","metadata":{}},{"cell_type":"code","source":"timag = []\nfor i in range(0,1783):\n    timg = test_data['Image'][i].split(' ')\n    timag.append(timg)\n\ntimage_list = np.array(timag,dtype = 'float')\nX_test = timage_list.reshape(-1,96,96,1) \nX_test = X_test/255.0\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T17:07:02.789627Z","iopub.execute_input":"2022-08-31T17:07:02.790629Z","iopub.status.idle":"2022-08-31T17:07:05.936282Z","shell.execute_reply.started":"2022-08-31T17:07:02.790591Z","shell.execute_reply":"2022-08-31T17:07:05.935169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = model.predict(X_test)\nprint(y_test.min(), y_test.max())","metadata":{"execution":{"iopub.status.busy":"2022-08-31T17:07:07.788071Z","iopub.execute_input":"2022-08-31T17:07:07.788455Z","iopub.status.idle":"2022-08-31T17:07:09.373376Z","shell.execute_reply.started":"2022-08-31T17:07:07.788424Z","shell.execute_reply":"2022-08-31T17:07:09.372401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot sample test images\nplot_images(X_test[:12], y_test[:12], 6, shrinkage=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T17:07:11.709727Z","iopub.execute_input":"2022-08-31T17:07:11.710288Z","iopub.status.idle":"2022-08-31T17:07:13.41086Z","shell.execute_reply.started":"2022-08-31T17:07:11.710246Z","shell.execute_reply":"2022-08-31T17:07:13.41002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Submission File","metadata":{}},{"cell_type":"code","source":"feature_names = list(lookid_data['FeatureName'])\nimage_ids = list(lookid_data['ImageId']-1)\nrow_ids = list(lookid_data['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(y_test[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('FKD_KB1V1_E_Result-Submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T17:07:17.875337Z","iopub.execute_input":"2022-08-31T17:07:17.875959Z","iopub.status.idle":"2022-08-31T17:07:17.975041Z","shell.execute_reply.started":"2022-08-31T17:07:17.875924Z","shell.execute_reply":"2022-08-31T17:07:17.974028Z"},"trusted":true},"execution_count":null,"outputs":[]}]}